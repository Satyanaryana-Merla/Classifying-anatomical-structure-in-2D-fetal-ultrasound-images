{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "image_label_df = pd.read_csv('E:/task1/image_label.csv')\n",
    "image_label_df['Image_name'] = image_label_df['Image_name']+ '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "image_label_df['Image_name'] = 'E:/task1/train_test/' + image_label_df['Image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(image_label_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1316 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the image dimensions and batch size\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='Image_name',\n",
    "    y_col='Plane',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 330 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Image_name',\n",
    "    y_col='Plane',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "41/41 [==============================] - 473s 11s/step - loss: 1.5083 - accuracy: 0.3575 - val_loss: 1.0776 - val_accuracy: 0.5125\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 450s 11s/step - loss: 1.1146 - accuracy: 0.5179 - val_loss: 0.8387 - val_accuracy: 0.6906\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 460s 11s/step - loss: 0.9746 - accuracy: 0.6098 - val_loss: 0.7041 - val_accuracy: 0.7875\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 442s 11s/step - loss: 0.8589 - accuracy: 0.6760 - val_loss: 0.5750 - val_accuracy: 0.7969\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 414s 10s/step - loss: 0.8495 - accuracy: 0.6706 - val_loss: 0.5875 - val_accuracy: 0.8031\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 444s 11s/step - loss: 0.8028 - accuracy: 0.7002 - val_loss: 0.6413 - val_accuracy: 0.7875\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 423s 10s/step - loss: 0.7806 - accuracy: 0.7188 - val_loss: 0.4932 - val_accuracy: 0.8281\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 421s 10s/step - loss: 0.7413 - accuracy: 0.7188 - val_loss: 0.5278 - val_accuracy: 0.8219\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 381s 9s/step - loss: 0.7348 - accuracy: 0.7313 - val_loss: 0.4723 - val_accuracy: 0.8531\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 406s 10s/step - loss: 0.7025 - accuracy: 0.7570 - val_loss: 0.4841 - val_accuracy: 0.8438\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 435s 11s/step - loss: 0.7014 - accuracy: 0.7477 - val_loss: 0.4959 - val_accuracy: 0.8344\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 402s 10s/step - loss: 0.6791 - accuracy: 0.7671 - val_loss: 0.4086 - val_accuracy: 0.8813\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 398s 10s/step - loss: 0.6664 - accuracy: 0.7671 - val_loss: 0.4559 - val_accuracy: 0.8687\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 419s 10s/step - loss: 0.6457 - accuracy: 0.7679 - val_loss: 0.4176 - val_accuracy: 0.8781\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 421s 10s/step - loss: 0.6383 - accuracy: 0.7656 - val_loss: 0.4523 - val_accuracy: 0.8656\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 416s 10s/step - loss: 0.5980 - accuracy: 0.7921 - val_loss: 0.3897 - val_accuracy: 0.8781\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 420s 10s/step - loss: 0.5795 - accuracy: 0.7928 - val_loss: 0.3978 - val_accuracy: 0.8656\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 418s 10s/step - loss: 0.6104 - accuracy: 0.7788 - val_loss: 0.3783 - val_accuracy: 0.8813\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 417s 10s/step - loss: 0.5745 - accuracy: 0.8014 - val_loss: 0.3879 - val_accuracy: 0.8719\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 413s 10s/step - loss: 0.5608 - accuracy: 0.8240 - val_loss: 0.4676 - val_accuracy: 0.8156\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.4570 - accuracy: 0.8212\n",
      "Test Loss: 0.4570, Test Accuracy: 82.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 20  # You can increase this for better performance\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_df) // batch_size\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "model.save('fetal_ultrasound_model.h5')\n",
    "\n",
    "# Save the weights of the model's layers\n",
    "model.save_weights('fetal_ultrasound_model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('fetal_ultrasound_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset and labels\n",
    "test_df = pd.read_csv(r'E:/task1/image_label.csv')\n",
    "test_df['Image_name'] = test_df['Image_name']+ '.png'\n",
    "test_df['Image_name'] = r'E:/task1/train_test/' + test_df['Image_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1646 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing for the test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Image_name',\n",
    "    y_col='Plane',\n",
    "    target_size=(256, 256),  # Assuming the same image dimensions as used during training\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 161s 3s/step - loss: 0.4526 - accuracy: 0.8396\n",
      "Test Loss: 0.4526, Test Accuracy: 83.96%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save classified images\n",
    "output_directory = 'E:/task1/classified_images'\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels and indices\n",
    "class_labels = {v: k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "hypotheses = {\n",
    "    'abdomen': 'This image is likely of the abdomen.',\n",
    "    'thorax': 'This image is likely of the thorax.',\n",
    "    'brain': 'This image is likely of the brain.',\n",
    "    'femur': 'This image is likely of the femur.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through test data and save classified images to respective folders\n",
    "for i in range(len(test_generator.filenames)):\n",
    "    image_path = test_generator.filepaths[i]\n",
    "    true_label = test_generator.labels[i]\n",
    "    \n",
    "    # Load and preprocess the image for prediction\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalize\n",
    "    \n",
    "    # Make a prediction\n",
    "    predicted_label = np.argmax(model.predict(img_array), axis=-1)[0]\n",
    "\n",
    "    # Create subdirectories for each class label\n",
    "    label_directory = os.path.join(output_directory, class_labels[true_label])\n",
    "    os.makedirs(label_directory, exist_ok=True)\n",
    "\n",
    "    # Copy the image to the corresponding folder\n",
    "    image_name = os.path.basename(image_path)\n",
    "    shutil.copy(image_path, os.path.join(label_directory, image_name))\n",
    "\n",
    "print(\"Classified images saved to respective folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "To test whether the model performs well or not, you can provide another image as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 666ms/step\n",
      "The input image is classified as: femur\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('fetal_ultrasound_model.h5')\n",
    "\n",
    "# Define a function for classification\n",
    "def classify_image(image_path):\n",
    "    # Load and preprocess the input image\n",
    "    img = image.load_img(image_path, target_size=(256, 256))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalize\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Map predicted class index to class label\n",
    "    class_labels = {0: 'abdomen', 1: 'thorax', 2: 'brain', 3: 'femur'}\n",
    "    predicted_class = class_labels[np.argmax(prediction)]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage:\n",
    "image_path = r'E:\\task1\\External Test images\\Patient01600_Plane6_1_of_8.png'\n",
    "predicted_label = classify_image(image_path)\n",
    "print(f\"The input image is classified as: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
